{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d53684f4",
   "metadata": {},
   "source": [
    "# Spam Email Detection: Data Exploration\n",
    "\n",
    "This notebook explores the spam email dataset to understand its characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fcb85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Set plot style\n",
    "import seaborn as sns\n",
    "sns.set_theme() \n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "# Add project root to path\n",
    "sys.path.append(os.path.join(os.getcwd(), '..'))\n",
    "\n",
    "# Import project modules\n",
    "from src.utils.text_processing import (\n",
    "    get_text_statistics, plot_text_length_distribution, \n",
    "    plot_word_cloud, get_most_common_words, plot_most_common_words\n",
    ")\n",
    "\n",
    "# Download NLTK resources\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de32dadd",
   "metadata": {},
   "source": [
    "## 1. Load the Dataset\n",
    "\n",
    "Load the spam dataset from a CSV file. Make sure to put the CSV file in the `data/raw` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c342ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set data path\n",
    "DATA_PATH = '../data/raw/spam.csv'\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "# Display first few rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f7b900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check dataset shape\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "\n",
    "# Check column names\n",
    "print(f\"Columns: {df.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cdd4747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns for clarity (adjust based on actual column names in your dataset)\n",
    "df = df.rename(columns={'Category': 'label', 'Message': 'message'})\n",
    "\n",
    "# Check for missing values\n",
    "print(\"Missing values:\")\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7247917",
   "metadata": {},
   "source": [
    "## 2. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32cc403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check class distribution\n",
    "class_distribution = df['label'].value_counts(normalize=True) * 100\n",
    "print(f\"Class distribution:\\n{class_distribution}\")\n",
    "\n",
    "# Plot class distribution\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(x='label', data=df)\n",
    "plt.title('Class Distribution')\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "# Add percentage labels\n",
    "total = len(df)\n",
    "for i, count in enumerate(df['label'].value_counts()):\n",
    "    plt.annotate(f\"{count/total*100:.1f}%\", \n",
    "                xy=(i, count), \n",
    "                xytext=(0, 5),  \n",
    "                textcoords=\"offset points\", \n",
    "                ha='center', \n",
    "                va='bottom')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb35171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze message length\n",
    "df['message_length'] = df['message'].apply(len)\n",
    "df['word_count'] = df['message'].apply(lambda x: len(x.split()))\n",
    "\n",
    "# Summary statistics\n",
    "print(\"Message length statistics:\")\n",
    "print(df[['message_length', 'word_count']].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab6790d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare message lengths by class\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Character length\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.boxplot(x='label', y='message_length', data=df)\n",
    "plt.title('Message Length by Class')\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Number of Characters')\n",
    "\n",
    "# Word count\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.boxplot(x='label', y='word_count', data=df)\n",
    "plt.title('Word Count by Class')\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Number of Words')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a56a61",
   "metadata": {},
   "source": [
    "## 3. Text Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664d085d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate spam and ham messages\n",
    "spam_messages = df[df['label'] == 'spam']['message'].values\n",
    "ham_messages = df[df['label'] == 'ham']['message'].values\n",
    "\n",
    "# Get statistics for each class\n",
    "spam_stats = get_text_statistics(spam_messages)\n",
    "ham_stats = get_text_statistics(ham_messages)\n",
    "\n",
    "# Print statistics\n",
    "print(\"Spam Statistics:\")\n",
    "for key, value in spam_stats.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "print(\"\\nHam Statistics:\")\n",
    "for key, value in ham_stats.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559958f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(14, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plot_text_length_distribution(spam_messages, \"Spam Message Length Distribution\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plot_text_length_distribution(ham_messages, \"Ham Message Length Distribution\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77ed0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate word clouds for each class\n",
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plot_word_cloud(spam_messages, \"Spam Word Cloud\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plot_word_cloud(ham_messages, \"Ham Word Cloud\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7f4d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find most common words in each class\n",
    "spam_common_words = get_most_common_words(spam_messages, 20)\n",
    "ham_common_words = get_most_common_words(ham_messages, 20)\n",
    "\n",
    "# Plot most common words\n",
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plot_most_common_words(spam_messages, 20, \"Most Common Words in Spam\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plot_most_common_words(ham_messages, 20, \"Most Common Words in Ham\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a659fd",
   "metadata": {},
   "source": [
    "## 4. Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d144e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc341cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import preprocessing function\n",
    "from src.data.preprocess import preprocess_text\n",
    "\n",
    "# Get a few examples\n",
    "example_texts = df['message'].iloc[:5].values\n",
    "\n",
    "# Preprocess and display\n",
    "for i, text in enumerate(example_texts):\n",
    "    print(f\"Original Text {i+1}:\\n{text}\")\n",
    "    print(f\"\\nPreprocessed Text {i+1}:\\n{preprocess_text(text)}\")\n",
    "    print(\"\\n\" + \"-\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1884b348",
   "metadata": {},
   "source": [
    "## 5. Save Processed Data (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d07ada4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess all messages\n",
    "df['cleaned_message'] = df['message'].apply(preprocess_text)\n",
    "\n",
    "# Save to processed data directory\n",
    "output_path = '../data/processed/spam_data_processed.csv'\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Processed data saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7066bef6",
   "metadata": {},
   "source": [
    "## 6. Conclusion\n",
    "\n",
    "In this notebook, we've explored the spam email dataset and gained insights into its characteristics. Key findings:\n",
    "\n",
    "1. The dataset is imbalanced with more ham than spam messages\n",
    "2. Spam messages tend to be longer on average than ham messages\n",
    "3. Common words in spam include terms related to promotions, free offers, and urgency\n",
    "4. Common words in ham are more conversational\n",
    "\n",
    "These insights will help us build a more effective spam detection model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
